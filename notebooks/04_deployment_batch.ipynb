{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd61dd0",
   "metadata": {},
   "source": [
    "---\n",
    "# Algoritmos para Big Data – Projeto\n",
    "## Parte 4: Modelação e Previsão\n",
    "\n",
    "**Dataset:** Flight Delay Dataset (amostrado e limpo)\n",
    "\n",
    "**Autores:**\n",
    "- Henrique Niza (131898)\n",
    "- Paulo Francisco Pinto (128962)\n",
    "- Rute Roque (128919)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c4d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/05/24 22:34:54 WARN Utils: Your hostname, MacBook-Pro-de-admin.local, resolves to a loopback address: 127.0.2.3; using 192.168.68.50 instead (on interface en0)\n",
      "25/05/24 22:34:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/24 22:34:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# 1. Spark Setup\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "spark = SparkSession.builder.appName(\"FlightDelayDeploymentBatch\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501fcaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado de: ../models/flight_delay_rf_model\n"
     ]
    }
   ],
   "source": [
    "# 2. Carregar o modelo treinado\n",
    "model_path = \"../models/flight_delay_rf_model\"\n",
    "model = PipelineModel.load(model_path)\n",
    "print(f\"Modelo carregado de: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29c9efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de voos para prever: 8500634\n"
     ]
    }
   ],
   "source": [
    "# 3. Carregar dados novos (neste caso, simulamos com os mesmos dados limpos)\n",
    "input_path = \"../data/processed/flights_cleaned_sample.parquet\"\n",
    "novos_dados = spark.read.parquet(input_path)\n",
    "print(f\"Número de voos para prever: {novos_dados.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837b4e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------+----+--------+----------+\n",
      "|FlightDate|          Airline|Origin|Dest|DepDelay|prediction|\n",
      "+----------+-----------------+------+----+--------+----------+\n",
      "|2018-01-06|Endeavor Air Inc.|   CRW| ATL|     9.0|       0.0|\n",
      "|2018-01-14|Endeavor Air Inc.|   ATL| XNA|    -6.0|       0.0|\n",
      "|2018-01-27|Endeavor Air Inc.|   LGA| MSY|    -8.0|       0.0|\n",
      "|2018-01-30|Endeavor Air Inc.|   DTW| MEM|    -4.0|       0.0|\n",
      "|2018-01-28|Endeavor Air Inc.|   MSP| ROC|    -2.0|       0.0|\n",
      "|2018-01-05|Endeavor Air Inc.|   DTW| PIT|    -1.0|       0.0|\n",
      "|2018-01-23|Endeavor Air Inc.|   RDU| LGA|    42.0|       0.0|\n",
      "|2018-01-12|Endeavor Air Inc.|   ATL| BMI|    64.0|       0.0|\n",
      "|2018-01-11|Endeavor Air Inc.|   SAT| DTW|    28.0|       0.0|\n",
      "|2018-01-17|Endeavor Air Inc.|   BNA| LGA|    34.0|       0.0|\n",
      "+----------+-----------------+------+----+--------+----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 4. Aplicar o modelo para gerar previsões\n",
    "previsoes = model.transform(novos_dados)\n",
    "previsoes.select(\"FlightDate\", \"Airline\", \"Origin\", \"Dest\", \"DepDelay\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c565a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/24 22:35:09 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "[Stage 38:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsões salvas com sucesso em: ../data/predictions/batch_predictions.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 5. Guardar previsões em formato Parquet\n",
    "output_path = \"../data/predictions/batch_predictions.parquet\"\n",
    "previsoes.select(\"FlightDate\", \"Airline\", \"Origin\", \"Dest\", \"DepDelay\", \"prediction\") \\\n",
    "         .write.mode(\"overwrite\").parquet(output_path)\n",
    "print(f\"Previsões salvas com sucesso em: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
